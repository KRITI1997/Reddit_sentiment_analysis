{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting praw\n",
      "  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 KB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websocket-client>=0.54.0\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting update-checker>=0.18\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting prawcore<3,>=2.1\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.12)\n",
      "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
      "\u001b[33m  WARNING: The script wsdump is installed in '/Users/kriti/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed praw-7.7.1 prawcore-2.4.0 update-checker-0.18.0 websocket-client-1.8.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(user_agent='Comment Extraction (by /u/USERNAME)',client_id='ENTER THE PERSONAL USE SECRET IN THE APP',client_secret=\"ENTER THE SECRET FOR THE APP\",username='ENTER REDDIT USERNAME', password='ENTER PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_list = []\n",
    "header_list = []\n",
    "\n",
    "for submission in reddit.subreddit('clinicalresearch').hot(limit=2):\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    comment_queue = submission.comments[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "while comment_queue:\n",
    "    header_list.append(submission.title)\n",
    "    comment = comment_queue.pop(0)\n",
    "    comm_list.append(comment.body)\n",
    "    t = []\n",
    "    t.extend(comment.replies)\n",
    "    while t:\n",
    "        header_list.append(submission.title)\n",
    "        reply = t.pop(0)\n",
    "        comm_list.append(reply.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_list = []\n",
    "header_list = []\n",
    "i = 0\n",
    "for submission in reddit.subreddit('clinicalresearch').hot(limit=2):\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    comment_queue = submission.comments[:]  # Seed with top-level\n",
    "    while comment_queue:\n",
    "        header_list.append(submission.title)\n",
    "        comment = comment_queue.pop(0)\n",
    "        comm_list.append(comment.body)\n",
    "        t = []\n",
    "        t.extend(comment.replies)\n",
    "        while t:\n",
    "            header_list.append(submission.title)\n",
    "            reply = t.pop(0)\n",
    "            comm_list.append(reply.body)\n",
    "df = pd.DataFrame(header_list)\n",
    "df['comm_list'] = comm_list\n",
    "df.columns = ['header','comments']\n",
    "df['comments'] = df['comments'].apply(lambda x : x.replace('\\n',''))\n",
    "df.to_csv('cordcutter_comments.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clinical Research Role/Salary Master Form &amp; Sp...</td>\n",
       "      <td>This is kind of scary...there are many CRAs ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinical Research Role/Salary Master Form &amp; Sp...</td>\n",
       "      <td>I saw that as more responses came in!! It real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Research Role/Salary Master Form &amp; Sp...</td>\n",
       "      <td>I think part of it is that CRAs can be employe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Research Role/Salary Master Form &amp; Sp...</td>\n",
       "      <td>There are also many getting overpaid but yes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Research Role/Salary Master Form &amp; Sp...</td>\n",
       "      <td>I noticed that!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Mega thread for 2024 raises/bonuses?</td>\n",
       "      <td>Your salary seems pretty low for your position...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Mega thread for 2024 raises/bonuses?</td>\n",
       "      <td>CRA - midsize CRO.  2% merit increase.  ~18% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Mega thread for 2024 raises/bonuses?</td>\n",
       "      <td>Vendor, 6% bonus, we got 3% merits last year b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Mega thread for 2024 raises/bonuses?</td>\n",
       "      <td>CRO PM. 135K. Successful performer. 3% merit i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Mega thread for 2024 raises/bonuses?</td>\n",
       "      <td>Mid size sponsor, Europe, 3 % with exceeds exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                header  \\\n",
       "0    Clinical Research Role/Salary Master Form & Sp...   \n",
       "1    Clinical Research Role/Salary Master Form & Sp...   \n",
       "2    Clinical Research Role/Salary Master Form & Sp...   \n",
       "3    Clinical Research Role/Salary Master Form & Sp...   \n",
       "4    Clinical Research Role/Salary Master Form & Sp...   \n",
       "..                                                 ...   \n",
       "194               Mega thread for 2024 raises/bonuses?   \n",
       "195               Mega thread for 2024 raises/bonuses?   \n",
       "196               Mega thread for 2024 raises/bonuses?   \n",
       "197               Mega thread for 2024 raises/bonuses?   \n",
       "198               Mega thread for 2024 raises/bonuses?   \n",
       "\n",
       "                                              comments  \n",
       "0    This is kind of scary...there are many CRAs ge...  \n",
       "1    I saw that as more responses came in!! It real...  \n",
       "2    I think part of it is that CRAs can be employe...  \n",
       "3    There are also many getting overpaid but yes, ...  \n",
       "4                                      I noticed that!  \n",
       "..                                                 ...  \n",
       "194  Your salary seems pretty low for your position...  \n",
       "195  CRA - midsize CRO.  2% merit increase.  ~18% t...  \n",
       "196  Vendor, 6% bonus, we got 3% merits last year b...  \n",
       "197  CRO PM. 135K. Successful performer. 3% merit i...  \n",
       "198  Mid size sponsor, Europe, 3 % with exceeds exp...  \n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.28.0-py3-none-any.whl (320 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>4 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai) (4.64.1)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions<5,>=4.7\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup>=1.0.2 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.1.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2021.10.8)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic-core==2.18.2\n",
      "  Downloading pydantic_core-2.18.2-cp38-cp38-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: typing-extensions, sniffio, h11, distro, pydantic-core, httpcore, anyio, annotated-types, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.2.0\n",
      "    Uninstalling typing_extensions-4.2.0:\n",
      "      Successfully uninstalled typing_extensions-4.2.0\n",
      "\u001b[33m  WARNING: The script distro is installed in '/Users/kriti/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/Users/kriti/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script openai is installed in '/Users/kriti/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.6.0 anyio-4.3.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.28.0 pydantic-2.7.1 pydantic-core-2.18.2 sniffio-1.3.1 typing-extensions-4.11.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "openai.api_key = 'ENTER OPENAI SECRET KEY HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/kriti/Library/Python/3.8/lib/python/site-packages (0.28.0)\n",
      "Collecting openai\n",
      "  Using cached openai-1.28.0-py3-none-any.whl (320 kB)\n",
      "Requirement already satisfied: tqdm>4 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.1.0)\n",
      "Requirement already satisfied: certifi in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2021.10.8)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "\u001b[33m  WARNING: The script openai is installed in '/Users/kriti/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed openai-1.28.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai==0.28\n",
      "  Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: tqdm in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai==0.28) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from requests>=2.20->openai==0.28) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from requests>=2.20->openai==0.28) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from requests>=2.20->openai==0.28) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from requests>=2.20->openai==0.28) (3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from aiohttp->openai==0.28) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/kriti/Library/Python/3.8/lib/python/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.28.0\n",
      "    Uninstalling openai-1.28.0:\n",
      "      Successfully uninstalled openai-1.28.0\n",
      "\u001b[33m  WARNING: The script openai is installed in '/Users/kriti/Library/Python/3.8/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed openai-0.28.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to authenticate with Reddit API using PRAW\n",
    "def authenticate_reddit():\n",
    "    reddit = praw.Reddit(client_id='6rNFU8zGBPWzHAqGeI16Cw',\n",
    "                         client_secret='ZRrVsrUQFRxc3vBoM1HBWGBebETEvA',\n",
    "                         user_agent='Comment Extraction (by /u/USERNAME)',\n",
    "                         username='Ok_Increase596', password='Hyperbola')\n",
    "    return reddit\n",
    "\n",
    "# Function to scrape Reddit posts and comments from specified subreddits\n",
    "def scrape_reddit_data(reddit, subreddits):\n",
    "    posts = []\n",
    "    for subreddit_name in subreddits:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        for submission in subreddit.hot(limit=10):\n",
    "            posts.append({\n",
    "                'title': submission.title,\n",
    "                'body': submission.selftext,\n",
    "                'comments': [comment.body for comment in submission.comments]\n",
    "            })\n",
    "    return posts\n",
    "\n",
    "# Function to perform sentiment analysis using OpenAI API\n",
    "def analyze_sentiment(text_data):\n",
    "    # prompt = \"Sentiment analysis:\\n\" + \"\\n\".join(text_data)\n",
    "    \n",
    "    \n",
    "    # response = openai.Completion.create(\n",
    "    #     engine=\"davinci\",\n",
    "    #     prompt=prompt,\n",
    "    #     #temperature=0.5,\n",
    "    #     max_tokens=50\n",
    "    # )\n",
    "    \n",
    "    # return response.choices[0].text.strip().split('\\n')\n",
    "     prompt = \"Sentiment analysis:\\n\" + \"\\n\".join(text_data)\n",
    "    \n",
    "     response = openai.completions.create(\n",
    "        model=\"davinci-002\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    \n",
    "\n",
    "# Function to generate personalized messages using OpenAI API\n",
    "def generate_personalized_messages(user_interests):\n",
    "    # prompt = \"Generate personalized messages:\\n\" + \"\\n\".join(user_interests)\n",
    "    \n",
    "    # response = openai.Completion.create(\n",
    "    #     engine=\"text-davinci-002\",\n",
    "    #     prompt=prompt,\n",
    "    #     temperature=0.5,\n",
    "    #     max_tokens=100\n",
    "    # )\n",
    "    \n",
    "    # return response.choices[0].text.strip().split('\\n')\n",
    "    prompt = \"Generate personalized messages:\\n\" + \"\\n\".join(user_interests)\n",
    "    \n",
    "    response = openai.completions.create(\n",
    "        model=\"davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.5,\n",
    "        max_tokens=20\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].text.strip().split('\\n')\n",
    "\n",
    "# Main function to orchestrate the project workflow\n",
    "def main():\n",
    "    # Authenticate with Reddit API\n",
    "    reddit = authenticate_reddit()\n",
    "    \n",
    "    # Subreddits related to health conditions and clinical trials\n",
    "    subreddits = [ 'clinicaltrials']\n",
    "\n",
    "    # Scraping Reddit data\n",
    "    reddit_data = scrape_reddit_data(reddit, subreddits)\n",
    "    \n",
    "    # Extract text data for sentiment analysis\n",
    "    text_data = [post['title'] + \" \" + post['body'] + \" \".join(post['comments']) for post in reddit_data]\n",
    "    \n",
    "    # Perform sentiment analysis\n",
    "    sentiment_results = analyze_sentiment(text_data)\n",
    "    \n",
    "    # Extract data for generating personalized messages\n",
    "    user_interests = [post['title'] + \" \" + post['body'] for post in reddit_data if 'clinical trial' in post['title'].lower() or 'clinical trial' in post['body'].lower()]\n",
    "    \n",
    "    # Generate personalized messages\n",
    "    personalized_messages = generate_personalized_messages(user_interests)\n",
    "    \n",
    "    # Output sentiment analysis results and personalized messages\n",
    "    print(\"Sentiment Analysis Results:\")\n",
    "    for result in sentiment_results:\n",
    "        print(result)\n",
    "    \n",
    "    print(\"\\nPersonalized Messages:\")\n",
    "    for message in personalized_messages:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn [78], line 82\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m text_data \u001b[39m=\u001b[39m [post[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m post[\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(post[\u001b[39m'\u001b[39m\u001b[39mcomments\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m post \u001b[39min\u001b[39;00m reddit_data]\n\u001b[1;32m     81\u001b[0m \u001b[39m# Perform sentiment analysis\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m sentiment_results \u001b[39m=\u001b[39m analyze_sentiment(text_data)\n\u001b[1;32m     84\u001b[0m \u001b[39m# Extract data for generating personalized messages\u001b[39;00m\n\u001b[1;32m     85\u001b[0m user_interests \u001b[39m=\u001b[39m [post[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m post[\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m post \u001b[39min\u001b[39;00m reddit_data \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mclinical trial\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m post[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mlower() \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mclinical trial\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m post[\u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mlower()]\n",
      "Cell \u001b[0;32mIn [78], line 37\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[0;34m(text_data)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manalyze_sentiment\u001b[39m(text_data):\n\u001b[1;32m     24\u001b[0m     \u001b[39m# prompt = \"Sentiment analysis:\\n\" + \"\\n\".join(text_data)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \n\u001b[1;32m     34\u001b[0m     \u001b[39m# return response.choices[0].text.strip().split('\\n')\u001b[39;00m\n\u001b[1;32m     35\u001b[0m      prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSentiment analysis:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(text_data)\n\u001b[0;32m---> 37\u001b[0m      response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     38\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdavinci-002\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     39\u001b[0m         prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     40\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m\n\u001b[1;32m     41\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/resources/completions.py:528\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, stream_options, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/_base_client.py:1005\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Jul 19 2021, 09:37:30) \n[Clang 13.0.0 (clang-1300.0.27.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
